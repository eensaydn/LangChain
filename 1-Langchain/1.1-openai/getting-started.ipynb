{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d11881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "# Langsmith Tracking\n",
    "os.environ['LANGCHAIN_API_KEY']=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['LANGCHAIN_TRACING_V2']=\"true\"\n",
    "os.environ['LANGCHAIN_PROJECT']=os.getenv(\"LANGCHAIN_PROJECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48055ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000002D018A590F0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002D01B8C5900> root_client=<openai.OpenAI object at 0x000002D01B8C5870> root_async_client=<openai.AsyncOpenAI object at 0x000002D018A592D0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae1085b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and get response from LLM\n",
    "\n",
    "result = llm.invoke(\"What is generative AI ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0cca094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Generative AI refers to a category of artificial intelligence systems designed to generate new content or data that is similar to what a human might create. It uses machine learning models to produce text, images, music, speech, and even entire virtual environments. These models learn patterns and structures from existing datasets and then generate new content based on that learning.\\n\\nOne common approach within generative AI is the use of Generative Adversarial Networks (GANs), which consist of two neural networks: a generator that creates data, and a discriminator that evaluates the data's authenticity. Another popular method involves using transformer-based models, like OpenAI's GPT-3, which generate text by predicting the next word in a sequence based on the context of the words that come before it.\\n\\nGenerative AI has a wide range of applications, including creating realistic images in art and design, producing synthetic data for training other AI models, developing natural language processing applications like chatbots, composing original music, and much more. Despite its potential, generative AI also raises ethical and practical concerns, such as the potential for creating misleading deepfakes or generating biased or inappropriate content.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 228, 'prompt_tokens': 13, 'total_tokens': 241, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BdwQ5hbT96Xb8j1FFhxFXR5aWz84X', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--a9731cf2-8c72-4966-94f0-5237980881f8-0' usage_metadata={'input_tokens': 13, 'output_tokens': 228, 'total_tokens': 241, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36f8aa69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Chatprompt Template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide me answer based on the question\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0042ee1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is an innovative tool introduced by LangChain to aid in the development and evaluation of language model applications (LLMs). It is designed to help developers efficiently manage and debug LLM applications while offering insights into performance and behavior. Key features of Langsmith include:\\n\\n1. **Logging and Tracing:** Langsmith logs interaction data, making it easy to trace and understand how a language model processes information. This is particularly useful for debugging and refining LLM applications.\\n\\n2. **Evaluation Framework:** It offers capabilities to evaluate the performance of language models across different tasks, providing quantitative and qualitative insights.\\n\\n3. **Tools for Experimentation:** By facilitating structured experimentation, Langsmith helps developers compare different model versions or settings, ensuring the optimal configuration for specific use cases.\\n\\n4. **Integration:** Seamlessly integrates with other components of the LangChain ecosystem, enhancing the capabilities of language models and making it easier to build complex applications.\\n\\nLangsmith is part of a broader movement to make LLMs more robust, reliable, and easier to work with in practical applications, catering to the growing needs of AI developers and researchers.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 222, 'prompt_tokens': 33, 'total_tokens': 255, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BdxMIJF5ij2tAFcAjowHqhvTcE61W', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--f1d7af73-9029-40ec-bbd9-d563b651b119-0' usage_metadata={'input_tokens': 33, 'output_tokens': 222, 'total_tokens': 255, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt| llm  ##prompt çalışsın → çıktısı llm'ye gitsin → LLM’den cevap alınsın\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you give me some information about Langsmith\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d24367c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdb7da2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a platform by LangChain designed to streamline and enhance the development, testing, and deployment of applications that utilize language models or chains. It provides a comprehensive set of tools aimed at addressing various challenges developers encounter when working with language models. \n",
      "\n",
      "Key features of Langsmith include:\n",
      "\n",
      "1. **Integration with LangChain Projects**: Langsmith is tailored to work seamlessly with LangChain, which means developers leveraging LangChain for building language model applications can efficiently manage their workflows using Langsmith.\n",
      "\n",
      "2. **Testing and Evaluation**: It offers robust framework capabilities for testing language models, enabling developers to assess the quality and reliability of their applications before deployment. This includes checking for model accuracy, performance, and consistency in responses.\n",
      "\n",
      "3. **Experimentation**: Langsmith allows developers to run experiments with different model configurations and settings, helping them to find the most effective approach for their specific use cases.\n",
      "\n",
      "4. **Reproducibility and Monitoring**: The platform provides features to ensure reproducibility of experiments and facilitates ongoing monitoring of deployed models, ensuring that they continue to perform as expected over time.\n",
      "\n",
      "5. **Data Management**: With tools for managing data inputs and outputs, Langsmith helps streamline the process of collecting and analyzing data, which is crucial for refining language models.\n",
      "\n",
      "Langsmith essentially acts as an enabler for developers to build smarter, more efficient, and robust applications with language models, reducing the time and effort needed to bring these applications from concept to production.\n"
     ]
    }
   ],
   "source": [
    "# Stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt |llm | output_parser\n",
    "\n",
    "response = chain.invoke({\"input\" : \"Can you tell me about Langsmith?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11170b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
